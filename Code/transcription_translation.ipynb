{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcription / Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install openai-whisper\n",
    "# ! pip install torch torchaudio\n",
    "# ! pip install sounddevice\n",
    "# ! pip install vosk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transcription only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting microphone... Speak now!\n",
      "Start speaking for synchronous transcription. Press Ctrl+C to stop.\n",
      "hey can you understand what I'm saying\n",
      "...\n",
      "all right\n",
      "not capturing\n",
      "...\n",
      "are you good at this\n",
      "...\n",
      "...\n",
      "why are you missing\n",
      "open Netflix\n",
      "play record my voice\n",
      "dim the last\n",
      "...\n",
      "...\n",
      "private please Brand\n",
      "what record\n",
      "...\n",
      "...\n",
      "can transcribe it please\n",
      "...\n",
      "\n",
      "Transcription stopped.\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from collections import deque\n",
    "\n",
    "def synchronous_transcription():\n",
    "    recognizer = sr.Recognizer()\n",
    "    mic = sr.Microphone()\n",
    "\n",
    "    print(\"Adjusting microphone... Speak now!\")\n",
    "    with mic as source:\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "\n",
    "    print(\"Start speaking for synchronous transcription. Press Ctrl+C to stop.\")\n",
    "    try:\n",
    "        while True:\n",
    "            with mic as source:\n",
    "                # Capture small chunks of speech continuously\n",
    "                audio = recognizer.listen(source, timeout=100, phrase_time_limit=2)\n",
    "                try:\n",
    "                    # Transcribe the audio chunk immediately\n",
    "                    text = recognizer.recognize_google(audio)\n",
    "                    print(text)\n",
    "                except sr.UnknownValueError:\n",
    "                    print(\"...\")  # Display silence if nothing is understood\n",
    "                except sr.RequestError as e:\n",
    "                    print(f\"API error: {e}\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTranscription stopped.\")\n",
    "\n",
    "synchronous_transcription()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Vosk is supposed to be faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vosk import Model, KaldiRecognizer\n",
    "import sounddevice as sd\n",
    "from deep_translator import GoogleTranslator\n",
    "import json\n",
    "\n",
    "def translate_audio_vosk():\n",
    "    model = Model(\"model\")  # Download Vosk model and specify its path\n",
    "    recognizer = KaldiRecognizer(model, 16000)\n",
    "\n",
    "    def record_audio(duration=3, samplerate=16000):\n",
    "        print(\"Recording...\")\n",
    "        audio = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype=\"int16\")\n",
    "        sd.wait()\n",
    "        print(\"Recording finished!\")\n",
    "        return audio.tobytes()\n",
    "\n",
    "    print(\"Start speaking for real-time translation. Press Ctrl+C to stop.\")\n",
    "    try:\n",
    "        while True:\n",
    "            # Record audio\n",
    "            audio_data = record_audio(duration=3)\n",
    "\n",
    "            # Perform real-time transcription\n",
    "            if recognizer.AcceptWaveform(audio_data):\n",
    "                result = json.loads(recognizer.Result())\n",
    "                text = result.get(\"text\", \"\")\n",
    "                print(f\"Transcribed Text: {text}\")\n",
    "\n",
    "                # Translate Text to English\n",
    "                if text:\n",
    "                    translated_text = GoogleTranslator(source=\"auto\", target=\"en\").translate(text)\n",
    "                    print(f\"Translated Text: {translated_text}\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTranslation stopped.\")\n",
    "\n",
    "translate_audio_vosk()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translation (very slow and inaccurate) and transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting microphone... Speak now!\n",
      "Start speaking for audio translation.\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  Put in薩麥克с big times\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  No one can welcome a beginner,\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  If you want to think, why are you good towards?\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English: \n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  My name is Andrew.\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  Thank you for watching.\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English: \n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  You asked me to collect on it hair\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  You can try\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  You do look so handsome\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English: \n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  I just...\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  This says recording. Okay, let me turn the next time.\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  Thank you.\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  They can, it's alright.\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  How are you in Marathi?\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  Something like a long longer sentence.\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  I need to think we need to.\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  Can you try something like this? I don't.\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  say no\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  How are you?\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  Oh nice.\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  Yeah? But like a not just too.\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  Let me frame a sentence for us.\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  Thank you for watching.\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  Tugasa Ahis.\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  Not looking good for Youtube, wondering what really that would've been done for a while dusk....\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  I am too young\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  No, I HAVE to forget\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English: \n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  No Huangaborian\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  Hello, friends.\n",
      "Recording...\n",
      "Recording finished!\n",
      "Translated to English:  I'm using the face model, I think.\n",
      "Recording...\n",
      "\n",
      "Translation stopped.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "\n",
    "def translate_audio_to_english():\n",
    "    # Load Whisper model\n",
    "    model = whisper.load_model(\"tiny\")  # You can use \"small\", \"medium\", or \"large\" for higher accuracy\n",
    "\n",
    "    print(\"Adjusting microphone... Speak now!\")\n",
    "    \n",
    "    # Record audio using the microphone\n",
    "    def record_audio(duration=10, samplerate=16000):\n",
    "        print(\"Recording...\")\n",
    "        audio = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype=\"float32\")\n",
    "        sd.wait()  # Wait until the recording is finished\n",
    "        print(\"Recording finished!\")\n",
    "        return np.squeeze(audio)\n",
    "\n",
    "    print(\"Start speaking for audio translation.\")\n",
    "    try:\n",
    "        while True:\n",
    "            # Record 3 seconds of audio\n",
    "            audio_data = record_audio(duration=3)\n",
    "\n",
    "            # Use Whisper to transcribe and translate the audio\n",
    "            result = model.transcribe(audio_data, task=\"translate\")\n",
    "            translated_text = result[\"text\"]\n",
    "            print(f\"Translated to English: {translated_text}\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTranslation stopped.\")\n",
    "\n",
    "translate_audio_to_english()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcription + translating the text (not audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to microphone... Speak now!\n",
      "Start speaking for synchronous transcription. Press Ctrl+C to stop.\n",
      "...\n",
      "English: can you turn the alarm\n",
      "English: my name is Esther\n",
      "...\n",
      "...\n",
      "...\n",
      "...\n",
      "...\n",
      "...\n",
      "English: drive please\n",
      "...\n",
      "\n",
      "Transcription stopped.\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "def synchronous_transcription_with_translation():\n",
    "    recognizer = sr.Recognizer()\n",
    "    mic = sr.Microphone()\n",
    "\n",
    "    print(\"Connected to microphone... Speak now!\")\n",
    "    with mic as source:\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "\n",
    "    print(\"Start speaking for synchronous transcription. Press Ctrl+C to stop.\")\n",
    "    try:\n",
    "        while True:\n",
    "            with mic as source:\n",
    "                # Capture small chunks of speech continuously\n",
    "                audio = recognizer.listen(source, timeout=100, phrase_time_limit=2)\n",
    "                try:\n",
    "                    # Transcribe the audio chunk immediately\n",
    "                    text = recognizer.recognize_google(audio)\n",
    "                    \n",
    "                    # Translate to English if needed (auto-detect source language)\n",
    "                    translated_text = GoogleTranslator(source=\"auto\", target=\"en\").translate(text)\n",
    "                    \n",
    "                    # Display the original and translated text\n",
    "                    if translated_text.lower() != text.lower():\n",
    "                        print(f\"Original: {text}\")\n",
    "                        print(f\"Translated to English: {translated_text}\")\n",
    "                    else:\n",
    "                        print(f\"English: {text}\")\n",
    "                except sr.UnknownValueError:\n",
    "                    print(\"...\")  # Display silence if nothing is understood\n",
    "                except sr.RequestError as e:\n",
    "                    print(f\"API error: {e}\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTranscription stopped.\")\n",
    "\n",
    "synchronous_transcription_with_translation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from collections import deque\n",
    "\n",
    "def live_transcription_rolling_window():\n",
    "    recognizer = sr.Recognizer()\n",
    "    mic = sr.Microphone()\n",
    "    word_queue = deque(maxlen=6)  # Store up to 6 words\n",
    "\n",
    "    print(\"Adjusting microphone... Speak now!\")\n",
    "    with mic as source:\n",
    "        recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "\n",
    "    print(\"Start speaking! Press Ctrl+C to stop.\")\n",
    "    try:\n",
    "        while True:\n",
    "            with mic as source:\n",
    "                # Listen for speech with a timeout and phrase limit\n",
    "                audio = recognizer.listen(source, timeout=20, phrase_time_limit=5)\n",
    "                try:\n",
    "                    # Recognize speech using Google Web Speech API\n",
    "                    text = recognizer.recognize_google(audio)\n",
    "                    words = text.split()  # Split recognized text into words\n",
    "                    \n",
    "                    # Add words to the deque and maintain the last 6 words\n",
    "                    for word in words:\n",
    "                        word_queue.append(word)\n",
    "                    \n",
    "                    # Display the rolling window of the last 6 words\n",
    "                    print(\" \".join(word_queue))\n",
    "                except sr.UnknownValueError:\n",
    "                    print(\"Could not understand the audio.\")\n",
    "                except sr.RequestError as e:\n",
    "                    print(f\"API error: {e}\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTranscription stopped.\")\n",
    "\n",
    "live_transcription_rolling_window()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
